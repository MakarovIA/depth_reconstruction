{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import pickle\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from skimage.filters import sobel_h, sobel_v\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_adaptive\n",
    "from skimage.exposure import rescale_intensity\n",
    "from utils.utils import *\n",
    "from utils.iterators import SynthiaIterator, FreiburgIterator, TUMIterator\n",
    "from utils.associate import associate, read_file_list\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "from models import interpolation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths are here\n",
    "#synthia_dataset = '/home/vladimir/external/data/SYNTHIA/SYNTHIA-SEQS-02-SOFTRAIN/'\n",
    "synthia_dataset = 'D:/Alice/Documents/depth_datasets/SYNTHIA/'\n",
    "synthia_val = 'D:/Alice/Documents/depth_datasets/SYNTHIA/SYNTHIA-SEQS-05-SPRING/'\n",
    "\n",
    "synthia_size=(480,  640)\n",
    "\n",
    "log_prefix = 'D:/Alice/Documents/deeplearning-semidense/out/test'\n",
    "\n",
    "vgg_npy_path = 'vgg/vgg16.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthia_list = get_file_list(synthia_dataset)\n",
    "synthia_val_list = get_file_list(synthia_val)\n",
    "synthia_list = [f for f in synthia_list if f not in synthia_val_list]\n",
    "\n",
    "synthia_depth = filter_files(synthia_list, ['Stereo_Left', 'Depth', 'png'])\n",
    "synthia_rgb =  filter_files(synthia_list, ['Stereo_Left','RGB','png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthia_depth_val = filter_files(synthia_val_list, ['Stereo_Left', 'Depth', 'png'])\n",
    "synthia_rgb_val = filter_files(synthia_val_list, ['Stereo_Left', 'RGB', 'png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 1280)\n",
      "uint16\n",
      "Train size 12972\n",
      "Validation size 1180\n"
     ]
    }
   ],
   "source": [
    "val_image_s = open_rgb(synthia_rgb_val[0])[None,:,:,:]\n",
    "val_gt_s = open_depth_synthia(synthia_depth_val[0], debug=True)[None]\n",
    "val_image_d = open_rgb(synthia_rgb_val[-1])[None,:,:,:]\n",
    "val_gt_d = open_depth_synthia(synthia_depth_val[-1])[None,:,:,:]\n",
    "\n",
    "print('Train size', len(synthia_rgb))\n",
    "print('Validation size', len(synthia_rgb_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(img, depth):\n",
    "    coin = tf.less(tf.random_uniform([], 0, 1.0), 0.5)\n",
    "    seed = random.random()\n",
    "    img = tf.cond(coin, lambda: tf.image.random_flip_left_right(img, seed = seed), \n",
    "                  lambda: tf.image.random_flip_up_down(img, seed=seed))\n",
    "    depth = tf.cond(coin, lambda: tf.image.random_flip_left_right(depth, seed = seed), \n",
    "                  lambda: tf.image.random_flip_up_down(depth, seed=seed))\n",
    "    return img, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_parser(rgb_img_path, depth_path, size = synthia_size):\n",
    "    # read the img from file\n",
    "    img_file = tf.read_file(rgb_img_path)\n",
    "    img_decoded = tf.image.decode_image(img_file, channels=3)\n",
    "    img_decoded.set_shape([None, None, 3])\n",
    "    image_resized = tf.image.resize_images(img_decoded, size)\n",
    "    \n",
    "    depth_file = tf.read_file(depth_path)\n",
    "    depth_decoded = tf.image.decode_image(depth_file, channels=1)\n",
    "    depth_decoded.set_shape([None, None, 1])\n",
    "    depth_resized = tf.image.resize_images(depth_decoded, size)\n",
    "    \n",
    "    image_resized, depth_resized = augment_data(image_resized, depth_resized) \n",
    "\n",
    "    return image_resized, depth_resized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 480, 640, 3) (?, 480, 640, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 5\n",
    "input_size = synthia_size#tf.placeholder(tf.int32, shape = (1,2))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    tr_data = tf.data.Dataset.from_tensor_slices((synthia_rgb,synthia_depth))\n",
    "    tr_data = tr_data.shuffle(buffer_size=512)\n",
    "    tr_data = tr_data.map(lambda x,y: input_parser(x,y, input_size))\n",
    "    tr_data = tr_data.batch(batch_size = batch_size)\n",
    "\n",
    "\n",
    "    val_data = tf.data.Dataset.from_tensor_slices((synthia_rgb_val,synthia_depth_val))\n",
    "    val_data = val_data.map(lambda x,y: input_parser(x,y, input_size))\n",
    "    val_data = val_data.batch(batch_size = batch_size)\n",
    "\n",
    "\n",
    "    iterator = tf.data.Iterator.from_structure(tr_data.output_types, tr_data.output_shapes)\n",
    "\n",
    "    next_element_rgb, next_element_d  = iterator.get_next()\n",
    "    next_element_rgb, next_element_d \n",
    "    print(next_element_rgb.shape, next_element_d.shape )\n",
    "\n",
    "    training_init_op = iterator.make_initializer(tr_data)\n",
    "    validation_init_op = iterator.make_initializer(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'IteratorGetNext:0' shape=(?, 480, 640, ?) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"IteratorGetNext:0\", shape=(?, 480, 640, ?), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    276\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 277\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    278\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3322\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3401\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3402\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3403\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"IteratorGetNext:0\", shape=(?, 480, 640, ?), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-ca837a3cbe41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0melem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1113\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \"\"\"\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \"\"\"\n\u001b[0;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \"\"\"\n\u001b[0;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    282\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 284\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    285\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'IteratorGetNext:0' shape=(?, 480, 640, ?) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"IteratorGetNext:0\", shape=(?, 480, 640, ?), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    i = 0\n",
    "    while i<5:\n",
    "        try:\n",
    "           \n",
    "            elem = sess.run(next_element)\n",
    "            plt.imshow(elem[0][1,:,:,:]/255)\n",
    "            plt.matshow(elem[1][1,:,:,0])\n",
    "            print(elem[0].shape)\n",
    "            plt.figure()\n",
    "            i+=1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training dataset.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_depth(d_tensor, mask_tensor, size):\n",
    "    eps = tf.constant(1e-2)\n",
    "    maxi = tf.constant(1e4)\n",
    "\n",
    "    d_cl = tf.clip_by_value(d_tensor, eps, maxi)\n",
    "    d_log = tf.log(d_cl + 1.)\n",
    "    \n",
    "    masked = ground_truth * mask_tensor[:, :]\n",
    "    nonzero = tf.cast(tf.count_nonzero(masked, axis=(1, 2), keep_dims=True), tf.float32)\n",
    "    masked_sum = tf.reduce_sum(masked, axis=(1, 2), keep_dims=True)\n",
    "    mean_d = masked_sum / nonzero\n",
    "    \n",
    "    masked_centered = masked - mean_d\n",
    "\n",
    "    return ground_truth, masked_centered, mean_d\n",
    "\n",
    "\n",
    "def preprocess_rgb(rgb_tensor, size):\n",
    "    greyscale = rgb_res[:, :, :, 0] * 0.2989 + rgb_res[:, :, :, 1] * 0.5870 + rgb_res[:, :, :, 2] * 0.1140\n",
    "    greyscale = greyscale[:, :, :, None]\n",
    "    g_min = tf.reduce_min(greyscale, axis=(1, 2), keep_dims=True)\n",
    "    g_max = tf.reduce_max(greyscale, axis=(1, 2), keep_dims=True)\n",
    "    g_normed = (greyscale - g_min) / (g_max - g_min)\n",
    "    g_out = g_normed - tf.reduce_mean(g_normed, axis=(1, 2), keep_dims=True)\n",
    "\n",
    "    return g_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_mask(img, sz, t):\n",
    "    img_rescaled = ((img - img.min(axis=(0,1)))/(img.max(axis=(0,1)) - img.min(axis=(0,1))) - 0.5)*2\n",
    "    grey = rgb2grey(img_rescaled) \n",
    "    grey_resized = resize(grey, sz, preserve_range=True)\n",
    "    grad = np.sqrt(sobel_h(grey_resized)**2 + sobel_v(grey_resized)**2)\n",
    "    thr = threshold_adaptive(grad, t, method='mean')\n",
    "    return thr.astype(int)[None, :,:, None]\n",
    "\n",
    "def combined_mask(img, sz, combined=True):\n",
    "    import cv2\n",
    "    resized = cv2.resize(img.astype(np.uint8), tuple(sz[::-1]))\n",
    "    blurred = cv2.GaussianBlur(resized, (5, 5), 0.2)\n",
    "    grey = cv2.cvtColor(blurred, cv2.COLOR_RGB2GRAY)\n",
    "    grad_x = cv2.Sobel(grey, cv2.CV_16S, 1, 0).astype(float)\n",
    "    grad_y = cv2.Sobel(grey, cv2.CV_16S, 0, 1).astype(float)\n",
    "    grad = np.sqrt(np.square(grad_x) + np.square(grad_y))\n",
    "    grad = np.round((grad - grad.min())/(grad.max() - grad.min())*255).astype(np.uint8)\n",
    "    grad_thr = cv2.adaptiveThreshold(grad,np.max(grad),cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 11\n",
    "                                    )\n",
    "    grad_thr = (grad_thr - grad_thr.min())/(grad_thr.max() - grad_thr.min())\n",
    "    grad_thr = np.ones(grad_thr.shape, dtype=np.float32) - grad_thr.astype(np.float32) \n",
    "    random = np.random.choice([0, 1],size=sz, p=[1 - 0.05, 0.05])\n",
    "    if combined:\n",
    "        grad_thr = np.clip(grad_thr + random, 0, 1)\n",
    "    else:\n",
    "        grad_thr = np.clip(grad_thr, 0, 1)\n",
    "    return grad_thr.astype(int)[None, :, :, None]\n",
    "\n",
    "\n",
    "def get_grad_mask(img, sz, combined=True, t=57):\n",
    "    shape = img.shape\n",
    "    bs = img.shape[0]\n",
    "    #return np.concatenate([threshold_mask(img[i,:,:,:], sz,t) for i in range(bs)])\n",
    "    return np.concatenate([combined_mask(img[i,:,:,:], sz, combined=combined) for i in range(bs)])\n",
    "\n",
    "def get_mask(sz, p):\n",
    "\n",
    "    mask = np.random.choice([0,1],size=sz, p=[1 - p, p])[None,:,:,None]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_regular_grid_mask(sz, step = 7):\n",
    "    z = np.zeros((1, *sz, 1))\n",
    "    z[:,::step,::step,:] = 1\n",
    "    return z\n",
    "\n",
    "def predict(sess, G_output, batch_d, batch_mask):\n",
    "    predicted = sess.run(G_output, feed_dict={target: batch_d, mask_t: batch_mask, d_flg: False})\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "def predict_sparse(sess, G_output, batch_d):\n",
    "    predicted = sess.run(G_output, feed_dict={sparse: batch_d, d_flg: False})\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_type_mask(rgb, size = synthia_size, mtype = 'rand'):\n",
    "    if mtype == 'rand+grad':\n",
    "        u = np.random.choice([0, 1], size=1000, p=[.3, .7])\n",
    "        if u: \n",
    "            mtype = 'rand'\n",
    "        else:\n",
    "            mtype = 'grad'\n",
    "                \n",
    "    if mtype == 'rand':\n",
    "        p = np.random.choice([0.05, 0.1, 0.2, 0.4])\n",
    "        mask = get_mask(size, p)\n",
    "    elif mtype == 'grad':\n",
    "        mask = get_grad_mask(rgb, size)\n",
    "    \n",
    "    return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11817708333333334\n",
      "0.148564453125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4c31add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAECCAYAAABOh0RhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztfX/MfklV32fYhV1XxWVX1F12W6SwRlqXX98gRGKM1i4QFG20YKxujc1GsYmGNhXaRG0TY+0fxphaKBYtNFakiIVYzFcKGNsEoQsuC3QLLJSU7Xd1BbpouymCTv9474XZs+ecOWfmzL1zX55P8uZ9nntnzpyZO/OZzznzvM+bcs444YQTTjghBg/b24ETTjjhhPOEE6mecMIJJwTiRKonnHDCCYE4keoJJ5xwQiBOpHrCCSecEIgTqZ5wwgknBGJ3Uk0pPTul9IGU0t0ppZfs7U+JlNIvp5TuSym9r7h2TUrpzSmlDy2/H7VcTymlX1j6cWdK6an7eQ6klG5MKb0tpXRXSun9KaUfPYL/KaUrU0rvTCm9Z/H7nyzXvzql9I7F719PKT1iuX7F8v7u5f5j9/C78P+ylNIfpJR+62B+fzSl9N6U0h0ppduXa1PPlcL3q1NKr0sp/fdlvj9zV99zzrv9ALgMwIcBPA7AIwC8B8AT9/SJ+PeNAJ4K4H3FtX8O4CXL65cA+Nnl9XMB/DaABOAZAN6xs+/XAXjq8vpLAXwQwBNn939p/0uW1w8H8I7Fn9cCeOFy/eUAfnh5/SIAL19evxDAr+887i8G8O8A/Nby/ih+fxTAl5NrU8+Vws9XAfi7y+tHALh6T993G4ilg88EcLF4/1IAL93TJ8bHxxJS/QCA65bX1wH4wPL6XwH4Hq7cDD8A3gDgW4/kP4CrALwbwNcD+DiAy+m8AXARwDOX15cv5dJO/t4A4C0AvhnAby0Ld3q/Fx84Up1+rgB4JID/QcduT9/3Dv8fA+Bjxft7lmsz4ytzzvcCwPL7K5br0/ZlCS2fgjPVN73/Swh9B4D7ALwZZ9HM/TnnzzK+fc7v5f6nAFy7rcefw88D+IcA/mJ5fy2O4TcAZAC/k1J6V0rptuXa9HMFZ1HuHwP4lSXt8q9TSl+MHX3fm1QTc+2ofzc7ZV9SSl8C4DcA/FjO+U+0osy1XfzPOf95zvnJOFN+TwfwtVyx5fcUfqeUngfgvpzzu8rLTNGp/C7wDTnnpwJ4DoAfSSl9o1J2Jt8vx1mK7mU556cA+L84C/clDPd9b1K9B8CNxfsbAFzayRcr/iildB0ALL/vW65P15eU0sNxRqi/mnN+/XL5MP7nnO8H8Ls4y31dnVK6fLlV+vY5v5f7Xwbgk9t6CgD4BgDfnlL6KIDX4CwF8POY328AQM750vL7PgC/ibPN7Ahz5R4A9+Sc37G8fx3OSHY33/cm1f8K4AnLCekjcJawf+POPtXwRgC3Lq9vxVmucr3+/cvp4jMAfGoNP/ZASikBeCWAu3LOP1fcmtr/lNKjU0pXL6+/CMBfB3AXgLcB+K6lGPV77c93AXhrXpJlWyLn/NKc8w0558fibB6/Nef8vZjcbwBIKX1xSulL19cA/gaA92HyuQIAOec/BPCxlNLXLJe+BcB/w56+75FcJgnl5+LsZPrDAP7x3v4Q334NwL0APoOzHe4HcZb3eguADy2/r1nKJgC/uPTjvQAu7Oz7s3AW1twJ4I7l57mz+w/gZgB/sPj9PgA/sVx/HIB3ArgbwL8HcMVy/crl/d3L/cdNMG++CZ8//Z/e78XH9yw/71/X4exzpfD/yQBuX+bMfwDwqD19T0tDJ5xwwgknBGDv8P+EE0444VzhRKonnHDCCYE4keoJJ5xwQiBOpHrCCSecEIghpJom/pKUE0444YSRCCfVlNJlOPvIwnNw9gUe35NSemKlzm3a/ZlxVN+P6jdwXN+P6jdwXN/38HuEUn06gLtzzh/JOf8Zzv665PmVOod8YAuO6vtR/QaO6/tR/QaO6/u5INWZvmzhhBNOOGFTXF4v4obpCwsWWX7bWYWHPe2R6Zqp/grhppsfwAfvvKp6/0pchZrva1nNZq29HnC2V79HtjsKNd8t420BV/+mmx8AgCa7lrniAfXP219P+V7freupxTfNDvW7Z078Kf73x3POj66VC/+LqpTSMwH8VM75luX9SwEg5/wzUp1Hpmvy16dvCWn/4qU7cMv1TxavS/ej2x7ZzlY4ah8uXrrjc6+P6D+HqPlbWx8tdSP9mBn/Kb/uXTnnC7VyI8L/4V+SUi4aCulBrddbHqTWntePGbD2R+rXet2yyCL9ibQROf5R/Yyw29uvlZitdkdtUB5b1N/auLU+r6jnHE6q+ewLd/8ezr7Z/C4Ar805vz+yDe/DHbUoKDS/RhBHK2objHV8oxZZxPOkNiKfeUQ/e30uy/aSRq1dC5HWNuRW3zhQH2rPw+uz1a4VQz6nmnN+U875ppzzX8k5/3S0fe+D6yW7iMGexUYELl66gx238lpNXdTUsgbLONxy/ZOnUqtWny1tWWxxz8i6iXp85a5r86B2vafMSPHksT3Ft1RF5lRL7JW3sYTPI3z7Qs15UV+t6Qup/kjfeuvt7atWJrqvUfDal8rvmVOdBlL+iKKmurRrUrutIUoPIvPFnnxqi0KYKTyXyItDZJSk2d9iQ2vJQ2tlWn0e3VfP5lqWb52j55pUgfaJYr3GIToMGRnWtOYiy3oti2Kr0Lx17KRx2VtR9bav5Uuj8/69m+1WZyErWtIgHM49qWqIyutQ9Ox0tQON0aqwR91vBU1hUWIafZjWOw5bf/zLozQ9feM2nd7NduTh40gcmlSlAxMresOdEXVrBMqRXs/BhufjNd4yPWj52NyWPqwY8ZnRmh89qSlPPesGGwHLx6T2zPF7xmFKUo3MXe6Nns/URZ7WetvwoDX/uAVxjv6UgVfNlf60fnStJzXlrefxMVLgUMG09yc5PO1PRapb5a22RC0VMNum0BvylYjMD7amJNY2Ro2zh0xKEeA5HKuV8c7pUWsgOt87SimPXnPTkOpWJ8ijcmOt7Y5Cq0psPa0ejRlSEkB7usQCC9Fa8/U9UUDLYVHEPGhV4N502GhMQ6rlLm7NIUUuopGf/eNej4ZHJbaqn5Fqohcjleke0MLhyHSAxXatjgUjPlLniXRHrstpSLVELYdUEupsu5SG6BxdFDyLslWpzfJcoj82VL4f/dG3LQl9ZF96BZE1yrKqdY9yt2AKUl2/Ts0KaUBaT1NHoDU/HJmXiiy7oudAZC9ipQov+lMjnrytRsDcvegDOys8H+OL+uSBJzcdWS7azhR/pnrhSVfmd168cbpDG2D7zxHWoG0cPQqAqv8Z+urB6nNLP7z9HXWgutczOOLz3gPWP1OdglQfma7J9997rXh/jwfOLRwp7bB1WFb73OkMC2QvP2i70X6M7Ndsz7Z382jxt2WDiypfs3W4v/1fc0blz4o1XCt/vGgJYUoCpaFZ60dianU0G5YJVFuUEbAeYkXalsJleuBg2QR7MEKdWm1HfHLFs37o2Flyx71io9ZH6dMQvfa5e61zZgqluob/FFIo1PNxEQvKULK0WxJqT7hpaZv6MYP6jERkn7jn1Kv4PP5F9cWjskelIHogrdMZIpaI8ocL/9ev/oskUOspYVmeI8+yzqic5hbYM3RtsdVKfrM/hwhY0lMj0x4zj3uvH1L9w5IqYN/hWgm3FkJYJgxHwFw7WyhNK/GPIL4W+9F5MIqtFaanDc+z2Tsv3fs8eyKCqA0icgwPS6rSYHrDMQ21EEVSrFKZnoc/2+4+gz8toXdkBDFqDFrGOCKV0VLeI2wi259h/pUo/TncQdUKjsysKYGyHv0pr682JXWw/i7rcn5Sfzk7mp+lHUs9Da31qB8ehT8KkUqzZZH2ho7SNUmRae8tz8PzXKx9s0YG0WM7E6ECbf5MRarc5CuJsLxWs0FfUzXJkVl5TwvZpDZKtE6OUfW8hGgNq2sbXCRa2pI2vZZ2LODGqJx7dC6V97j3tba0jX/F2q4X3NhFz7PziKlI1TM5SrVZ1pcmrJR3rKlVmgqw+FnDqEXQ22b5u1fRROZuqU1vHtUbDUT4btncaVTU40NtY2mJiLR8p9bWzNiC9KciVQ3lriwpyhWUcGnYv17ToOVKWwmo1t6Ksl9bh9yWNIsXo5Rfa9ujFr5345Vy9ZxNKwlq78vrVv8817l2o+dvVJprJKY7qNIgqc1eUDVKJ7uHPLdKtM+W0G9FzwGT5eCndZxmGV9LH/fwZ4TNXtuaso7w+VAHVesXqljCMi687wUXGnHhmHYI4dlBI3Zv60HCLGjJPUeo5i1y2z1jXlOmlgNEzha1EzU/Rxxkthz2SnY810dhClL94J1XAdCJonXQa4cb3KSTFKo1FKX+epP9Xt9bbNfaiK4/Og+twRoWt6LneUoHoi05UE5weEi5rFtrzzP3avN4rdubV+5B5JyYglRrkHKnWhLdehhR/ubymF7SkCZHy+FTbecdOemsi8q7+L1j0Gsv4hCo1w8tfWTNw26ttmrteRRrbR7PEF1F+nIIUrWA5kMj4FEg3OGYdFg2EiNCJk7ptYZaXnKw2mtJL4zwo+cenUP0tRU9EZy3DAdvimBkqsUrZiJSTocmVSlkb1Gw6+C3hs9U6a62OJXas0Bqisg7KbxhJfd+BszokwVcCKyF8RZYPk3Qc/rP2W3xbYv6UpQ7oq0Vhzr974GXMLnJ5zlllsK6qJPIWU6DtwLX36hT4z1Q8zm6TxH2uDk+y7h71mYrDnX6r2GLU0tav1SZNRtauE/rRE7C3sMuem+GvJaGWgg9k/9W9c+FpiPSWKs9q281G9J7ipa2rPOVXp8pH30IpWpVgb3oIT1tF99SUc2kHoDYMeXuA/KnNbbwYXaUc2/FkfvTgpNSZcDtkD25khpad3PrJw5GYs8FUzuEaDlEq0UfZZnWw7OaD0D9Y3JeUFu1XH+L/Vq+ttcmvce93gP0/MR74NyLQ5CqBdGhUuupIbf4vlCUgTXE7L1v8SEa0gFS62GgZTOQ0lAt/kZtCpaNS+vPSGipN4svUUJtqvBfO4ygGE1WvfY9IT9NFQBy/jYqtD1PZE9D3Nn75X3G2vXavRPicMjwn5sYI0I6DhHSXzvx52xzOUFtt+TU0dYfF6Gwjpl0INNiS4Nl3KPRktZo+WhQyz0KGhqfB8zWlylIdf3b/2h4wswo6c/lc2jur2yTe79HbrYnjLXAcnI84tAx2iYH+my1MLuWk+QiEfq6tllYP30wC3pJkcvbRxOtx94UpLr+7f+KVvVDUZs42kGId9LREEwiyJ4Jb5kw0bkybxmKvVTECNLQCE969txm4tmcLJtxrc5KwlpqQbvm2Rhannfvs+KeQ8v61eCxNwWpUtROfctyW8Dji2XCt4K2oS3OSDKLODjaKhRf25LeR/rR+qxrarT0sTWPTkmeO7gq79Nx0QSC5H90ZGBFRJuRfldJNaX0yyml+1JK7yuuXZNSenNK6UPL70ct11NK6RdSSnenlO5MKT211bGtHs4ohUZBF0KLgvX4FTl+HnUjXa8tuEjC1VINGrnU0FrWo4I0AqQHn9IcskQ03BhZn3PN1laYLZe6wqJU/w2AZ5NrLwHwlpzzEwC8ZXkPAM8B8ITl5zYAL4txsw8t+UKOIKIXfsSB05bQDuLWaz250j0WSS3V4r3H2e0NRbl0gpRa4H73qHNr1BgFT1sjorIIVEk15/x7AD5JLj8fwKuW168C8B3F9VfnM/w+gKtTStdFOUthHcwWNcoRRDTxzUKkvePYQ5plrm+L8ejpa2u+zuuDpBhLgquRXeQhLFXIlja91yzQoqAeOxYftzio+sqc870AsPz+iuX6YwB8rCh3z3JtCCzhpOdwZ3QessyXjdpdWxTWnqmW1gU/8kAusj3OhmferuAIvTVcb0FrmswbuXj7pOWnrXUsPu55UJWYa+xfF6SUbksp3Z5Suv0z+HSwGw/eXWu7GTdhPTmxms1SiZUkQkk2YkFoCqY1lzgjuDC4JZS3lo2wbSWmWp8sJBP5rEeIjhZEnH9s0ZdWUv2jNaxfft+3XL8HwI1FuRsAXOIM5JxfkXO+kHO+8HBc0eiGf4JZbVJF0PIQKFFK5EmJtgVHy89Gw6NmtDresesZ61o4K4WgrT5a51ZNJbeuhVZ4+mtNrYxcI62k+kYAty6vbwXwhuL69y+fAngGgE+taYJR0AhP25W0nEnPYctqi6rT1QZ3LUKlev2LmlR7q5ceRIXP3jocOXLXtBC0NXqyzLXa3GiZOy352BZIzzRKrVtg+UjVrwF4O4CvSSndk1L6QQD/DMC3ppQ+BOBbl/cA8CYAHwFwN4BfAvCiEU5boYX+1pxJ6+SlC4BTrXsRW2S7kSoiAr2kOIIwLOW9hNkSfbUq3ajn5hUy3JppaTPiENRTf6ovVCnROgG8aCGGCJ+4MM9zyhrtQyT2UN2evsw2ftQOnRuWNqRylLi27ntEeyO4oMUv6xeqTEWqLQtkFLSJrl3z2JaItcfPPRGV1/XkOiPmTOSzjWq/1wdtXHpJaktC3Rqaz4ck1a3hVYhe2zW1QSd35KYyQoFrZbi+tMCahpHGrEXlWWDZZL026PURJFTaBmLU3h5RQc1ebzuW+ueKVLdWDUC/0pKU6ApNqUYs4B6/vXUAnkyj8q2S0qqVmxXc8wXGHDa2lPPWaSW6kemn6I314qU7cNl1d58fUgXmUx2eehZFas197UmwIw5QpLa4Mlo7I0LSI4avJXr7alXQRxqnHsI9N0p1VpVmJb3WQ6hRYWwPNGW9vm615623whs2ewh8hjH3Ypa54sFRfD43pGpF9EFFb93eUHrGhS0plxl95TDrBj3SD2Bc9HBE9PTrkP9OxXO4YQkHLXZbw1xLu73oPfRpqWetc/HSgz/3eIQFuJWPvfl4azmubNRz0Q5WPYis08MPK7aYA4dTqpGJ51mIgDvc6TkRHn0AoNm3qKOZxn4WeFJDs2L0CfxeB7grDqlUt0RraM5dqymGmr1VUZQ+9UyWiL612F8nea39Mr1xntES8Xg+BdED69ysla992qMn6qvd70nZed57cThSrSkkK6KIhN7jDlG4dms7Mk1fjCQhy2LwnPxb6s6suKLQ0kcLuXLzo4ZecqvNV+53rZ4FPfPemgLwfvKkhsOF/xZsGRaMaKsMs4H6QtvigM5z6CF9cmH0c9k7PLS0qRHODCmALXzo+dTHnn3/ggr/a4dWZRktZG+Bl5QsZVabayi9KpMyTdB6COFVES2qQ0pjRCsCrV1Le9Gw5gS5Z0c3UnpvRVSfpHakqKuEN31jWZ8WWDervXEuSNVyAl8SlXXHiwi7PQpP2wxKcm0J/7Q2POVnmry9iO6Ld4Mtn2U5P6lv0UQqzX9pU7KkorT56JlDrWQdMUZR4zwVqY5Uj1yu06IKege6nJgted9SrVKVyi2Oo5Ael3e15BM1e97c4kjVR/3iiHN97c1htvjA2bSOcy3aoPPQe+BkvVe2Zy3rQdTamSKneuFJV+ZHvffbTGW9eUDLJIhot+e+RzlT4vEo7x6U4WnrmHrr7pETjYJlwyvHc6u+RrUzYnOKwMhxPFRO9YN3XmUu6xkwSSVqSpWDJdfUsjtbdlzL4VSrAmlNIdT88ZaRxtbzrEcqdE5V10DTNes1GmmU5aP8s/rYA08U5/Fvi3noaafFnymU6l5f/VdD664XuVtyilQ61Bh1ImtRxdF93lP9RKq5nugmEjTKGdHu3s9tNA6lVDVE77gjD3W4etKhkiUPR+3VfltgUb6ee6vNnnxorT3LmLW23RJ1WEE3PmkT5A6uyvc1f62+cK+tsChLTz50BFrOLEZgalIdsfPVwvhoRBx21WAlndWfqPY4myWRaITSsrn1pFg4WNI6Vls1n7S5zB1EWvy1wJLiscwfSSh4/Rm5FrxptFG+TEmqo073NPt0YlmIobXNiBwtLcepO6p8rD5a2/T4ROtY1K/1upUMaves6Q8JEjm1RiqUYFvGzFLfelBGc8MWzKJMWyKpVt+/IHOq3gkUbbtWjgunLbtwueilELo3R2z123PPcr/F1976Pba4jbM2NiNzkpztiHZHjVc0Iuyfm5xqFLy5n9awvXYSz73XVFlP+oAL07Qcb4u6taIldK9hREgnpTJq7db84JQSfTZcjlWDR81z41JT3hbbvbnaVl+8fm+Z752CVG+6+YEQO1Ko3rpLRRwSaCHX+ptTpZTsan5IaQCqXim50kXRk9OLPACx3O8lUMvmwaVpWlMXWt1yM+vJIZfXPekca5qrpe9RaaXSVi1V04IopTwFqXo+p+pBb27Wmwe0QiJJOrk5kitDNvpes0PvU4LlyLZGOq0LyBM11HLPLddL255n6s1ze/yR1GoPLH5w4X9PvpRTnHS+toJLi3HiaWQe14Jzk1P15jJb1GsvSVv8ou8pUXJtcyG+RVHQ8lyb3H1vX6IwOu/W4gO3kFvmlfXZRY7BiPGc4Rn1QurD4XKqXoVD4V3stdyn1EakkijtaKFcjdDKMut7S2hbU8jSfU/IbIVFEUePfQs4Ql2vc8rXm3+tqcuIlEfZVvRYevzzzCmrnRkwDalaHkbvYtXIxhuyeSePFq6U1yUiq/mmqUyuzyVxam3SPN8oJRKdq13Rk+OrQUpNcPlRi39SWoi21QNNVW9NTrU5ZXl2I+Zjr72pw/+WUEh7QHuEJV5C6gkFe1IbVp96bADtKQrJTqR/LSrLk3+0ztVa/V5bHswczm/t2+HCfw6eQ4xanZ7kuwecIqz50KpIaNla6KmlBDil1eKTFd7noZGYRw1y7z3+lOU97XKpC++z1tIgrWH30aD1OaJfETamJlUrLIvGcg/gwyFPGF4Lp6jNWp7Yk2vmwnguVyq1ZSnXA29/LBtSS7stB0mt7WrXvHYpmXKk4slNW9ucKd9ZSxNZ12yLfSumJlXrANUmW2mvFk5zdryKWSNTapPLbWq+ce+5kF86OPGgNR/Zu5C8+e0emzVY8n21TV3y26uwa/Wk5003W+s4tpAw5xO1NxLWNQuM82fqnGoLeol1BLjcJ8DnF1tzsNZ+aeMTsYi0dkfke7W2Wu+P9qUcCyB2vEf3bZYca21cR6x/a051KlIdMRgRE3fkwU8rAXiv9/gYadfS1p7Y4sBn9FgC/hzryPJlHU1QeNs6HVQZUMuXWKHlEbWwTboeRVK19qU8qOdgJWqS1Q7BPBgd9kXaH02oaxuj8pQtKR9PusUbEdE2vPMqihN64H1W0yjV+++9VpTzVkghwYrehzAyhG1V1FYFRH3fWx3ONIbR7fWo0r2fC0VEVBVVfu/6h1OqXOcidtyIAxvgwQ/ActhFX0vlvIcGFNZ+cQdknvat/lhhHUOvzZ4UUWt76+EP9+yt/vRsCFscKFoIKGozsPo1a/Q0Daly8D50bx0PrCGblDcqwU3QcoHSsqUtep3a+EKAJZXiQUt0QOuXz68k9y0IQjsE7W3TIiRaMSKF5RnvWjt0o7SiSqoppRtTSm9LKd2VUnp/SulHl+vXpJTenFL60PL7Ucv1lFL6hZTS3SmlO1NKT3V7tUDKhe4BGgZpqOWNaH5NuufJX7WMz1ZEVGuHI6la3pD6MEL51tqXNsuRz6K2kUTm/71l9l6jgD8yiLBFYVGqnwXw93POXwvgGQB+JKX0RAAvAfCWnPMTALxleQ8AzwHwhOXnNgAva/KsAEdoIx9gbbJGPjitnuXUs/W0d4sF0KPSZlgcVrv0GVhz3D1tcu1LUY63fa/Kjcplb0nU3rSZB1VSzTnfm3N+9/L6TwHcBeAxAJ4P4FVLsVcB+I7l9fMBvDqf4fcBXJ1Suk5r46abH1AXOrf7j1QmmkK2krpngnvap/dbT3t7w7oWMvOOmQW9innk5uI5uY4I/z02I8ctauOoba4zKGELXDnVlNJjATwFwDsAfGXO+V7gjHgBfMVS7DEAPlZUu2e5JuKDd15VJQftgMVDuBZwE0ZSI5IPaxmL6pRseMJ/CyLHacsc2yj7reG6NI5bRQBecPPK42trJBH9PGvPqvfQNwpmUk0pfQmA3wDwYznnP9GKMtce8rmtlNJtKaXbU0q3fwafNvlQTgQpHI/YNbVJ5FWgtTysFirSXVoi4NZQJmJybZGG6U2jSNdb1Dr3nEp7rTnVKFjyrOXB2oxoTU3M0h8TqaaUHo4zQv3VnPPrl8t/tIb1y+/7luv3ALixqH4DgEvUZs75FTnnCznnCw/HFWaHW4mhJdzhSEwivt4HWqtvDe08pB8xCa2KRVOFtU88cG1YlNZWatpLpDOq2V5EbnzS847CaPK1nP4nAK8EcFfO+eeKW28EcOvy+lYAbyiuf//yKYBnAPjUmiboRW2Xihp474GDJWy3pC3odVqWyy/VQvpZdm8tfdOyiKjS6o1EWiD1YU+16plnElrKt45pLZIry9XWi8XOFqj+RVVK6VkA/jOA9wL4i+XyP8JZXvW1AP4SgP8J4Ltzzp9cSPhfAHg2gAcA/EDO+XatjQtPujK/8+Lnxa3l1Fu6L9XvefBaDo3LuXIESCdFjy+RpDAL6faitvFZN8ie8Sif86hxHWHbOybW8ZwFUT4e8gtVarDuZt4B9BwI1drgymikSsvXbJd1W/sXvRC2IhFtgW+xuL3z5Dxijw1j641EwqFIlSrVFd7F4pX+NbuWBe21Q+tppEDLcX5HbCLeMY442NlikYwmt942I/zbksAjor0jR1mHIlVNqfYeRNVSApyNXjLtCZl6VaUlxXCUhXjktsv2R0ZPeyMinTJqfFp80+ocilQlpQq07WyWNIFWV8qLlnUtZG9ph762lLf6rNmq+WeFNTz32qpd712wEaFm73Oz+NHShmVuWf3aK60y46ZyKFL1fvN/D2nW7Jahdu+kkpSw1K70Xrom+W4l66iJq+WFR+VvZ8kL753nHYWjRhgj0i9ruUOR6oUnXZkf9d5vA8ATZvTikUAJtSxvSR9wtjhlG5lX4tqiZbwqpsUPi7qPxJEIq3UcLPWiQufelFT0XIpCpD0rqV4e0loQOKWolaUo62rgJogW3kshP0e85UOk/nhCc8nZREghAAAgAElEQVTvsi1PKmIUCdXsRik2bk5oCpnzcfQYSGRD/bbYKutoG2EkoUrjQ69phGohYA3Rz2ePjXcKper5SJWkhGq7pzdpTclWQ6vy44i8tqlIk1YjlNJPz8bV0gepjLbQWvJ+synVnpRNT5tA+5/ZjkzTeGyOfJZ7KNWpv6Qa4FXYxUt3iJO4/CnrSwqCq19iVYSlMpR81Eit/F3671E2lBA5VUNBfZfKl/3WNhJpfDRoSkdTd0dHL6FankNLNGfxz4Lac6KRlFTeGnG1zAtPNNfTTonpSZWbBBpJcCTIEYYU5mikQ0Nvrh36w6UA1h+6AVAfqO8SqA2NIKV0hKSWKWobi9WPsi3JP+19hMKLhHfxcmNcG0OpTclGS2rAA+umoG380nz0tBf9PMu12YJDhf+AHDLT11K9sm4ragqgxV6r31wKREsr0MVvWRi19AJtu3UsrGkBj42Z0ZIusqYYWp9H5PhFtc3N8ZF+SDYuu+7u45z+S/9NtQdcmGopp5W1tmcJ3bk2reEUZ9OSmrCGnJ4yNSL0TGgPEexJnlu2HUUILakISyoqEtzckdrfGocj1fUjVdE7m4YaEXgghc4jJgO3WfTs3jWlz/VFImotitB8kPzhyrXi6Ap2a/9HtudZHzMR66E+p+r98H8Jb85JqrfHQ7MqshXaQpPITwrNubplO9aFbU2/1GBNTRyJHDlYNzOp3iifAP+fNXujkpYwfpbn7VGq0xxUlQl2T5L4lusfemi0/njqWX2SfGtNakttcX5yfbD4wU3i9RpdUPR3aZPWsfapdp/zTSprSZN4EGnL0ob0LLy+lfdouZZIyzuu5eagRTNam1bfRiN6Dkzx4f+bbn4At1z/LaG7UpTysd7XcowWX6W2PJuL1T71mSsrqdjavdJOhCLRfG21WWKLRUvbaEnZcDYiUPrR6o9lw+9JUXnRO7ZymbtN9g4V/nsGq5ega4s8Ms8nEbE33Ofs1uxwtrS+l5BSC1qdsq7Ufs2vWULCUbCG1Vo6JyIl04OezbQlj+pNYbSMyxdMTtWC0fkojwL2PFxNCdbqcOEcR8jW9muTlRK5xUfOr6g828zEO9q3FlKS7ESTc6QwiiBKDw5JqqPU5V52LO1QWMhCQ03dWtSlpV2JtC3pCquakK5pPs5KpBQ9oS3g/4SFlyC3iApmfV6SX4ck1RLeAY9UOXvDEjKv5Sz5TWk3t6YdJB+9KsHiY+uhgUfRaOjNsXvai57jNeLkIpTafPCQ92rb43ML9lrDhydVCdEDOoq8e+tIdjhEkFlLez35MJom8BB8j+Ku+eRJ5Yxoq7euNDYzRIFHEDQaDk2qexPn3ugNDTl4ybNGnNrCbVWGXGhbQ2/KodZOFPF53/eWs/oViZnXWYRvhyLV8kuqOeypDmf2xesDBw/ZcItbChE94aCW9631yUokNUhEZSm3Bbz5Zk96xhNd7D2PV3j63mOrxKFIVfrb/63Drq0V8haHMJY8mSXMX99r6rSs0+Jn2S59b6kn+W9pW2tTG6cRIfx5Qs/m2LrZjsLhSLWWU60tYkuSfuuHMcKPPSdV7aCDlrXm/az3Sh8opMVXU6lW8qRlOV8iCdaySbWE/LV1MhMsRLplH84dqWqYhUSt2CP/1bOYpLBees3V5e5rqrmWRqj5K4G2z1232hxFsqutlj7vOednzde2RFNce+eGVFsT86ND+RlC+7JulAK29At4qFpdr0l2JRtS29x4S21I7dT6UMLad0r2ZX2pDe9zqc35lrnVKzyOSPIlIvp6aFL1TJ7zoEhb6+6V0gB4ddqSG6ulcSgkpanBo9BbFL2VYCOeZ0/apQVbtbMHvH04NKm2glNR5b0tlGMLvIt37xCvBJdf7VG99DpXTkKPUrXY8apPWl6bnx5YiX8kAW+Rm62llGrXon07F6QqTYqIgZIUkSX82yMn2mO7J3Uh1ZUUay0VUKKWT6X3PETNwaMCrXXKevQ19almWyOLlg21dY5EpZS8PkSgVXhY+nwoUqWfU5VUi3fA9gxRtmq7plSAtpDZAo3sam171On6PpLgaD8kW7RcbQ5a5m7L3PDWGR3VRAuLntSMt64VtM6hSHX9nCqFhyyk6zWV1hrGbBH+1Nql1y2I9lPb4TVi1F5TP2v3aZmWPlB4xtibdtiCWLdIFe0pWiRE97vs4+FIVQr/V9QWVQRa1MBW4ZGUrgBiPnDvQS1E1eppkYekdqV2R8LStkf1luWtG0SrOuV88UY0nD+1tkeoRa1eTWBER7eHItULT7oyv/PijQ+5bg3LaJ1ZQu8eH7wLVqojoUfxROTqJJse1RoNC/GUqKVVPCkCrXwNlrxrbdxGjesWirlsy7qptYz7oUi1VKqaIivRE555Bt9SPhq1xcFhiwVBic/iZ41QLYtu5jAT8P8RgBaBrdei+zySNGd5NtaNWauvlT0sqXpgCTfXci1EvXWulPowapdvTXNYCbAs00OmPZByvL1qULO9wqNgOTLlyvX6z4FLt4wK4SPQo7atRHtuwv+Wv6jS4FW4XB2NRCyhQ+8ClmxvHf568nvWsNabI2tFdA7PU3+FJUdcu14b/5nU4khYNwGPCPC0bf0X1VOSassOai3rzX3Rcr0PStsxt8w/aagl+jWlRtMDkkqNIK2evLClTtRipG1LZBlBrrStFl97bLS0GTXOI+cDcI6UKgePerLa42BRZlq9iHDEi54QqSyz+tOiUL3KqhZac2VW/zz9svgyCtIGul7jxqTEiM3pPGELJR9GqimlKwH8HoArAFwO4HU5559MKX01gNcAuAbAuwF8X875z1JKVwB4NYCnAfgEgBfknD+qtUFP/2luab2mYcQu6yHbWt7WSyJc2RZY63Pqki5kaeFL+dPynuSTt3+RhBqFHpVU21C9ZLwX9oiyIonUUj6SVBOAL845/5+U0sMB/BcAPwrgxQBen3N+TUrp5QDek3N+WUrpRQBuzjn/UErphQC+M+f8Aq2NWk4V6HtY0YTbm7M9otLgFnP5upbSoGW36Pus41vbGDTVGhXdzDo2PdDmVoR4GRL+p5Suwhmp/jCA/wjgq3LOn00pPRPAT+Wcb0kpXVxevz2ldDmAPwTw6Kw0JH1OFfCRlAc9k9KS1ypRU2st7XrD+BZI9aVwn0JStz2T+zyRQUtOXYqIIhTb0cd2hP+lTSupXm4xnFK6DMC7ADwewC8C+DCA+3POn12K3APgMcvrxwD4GAAshPspANcC+Lhk/4N3XuUiqRXWsLYsr9nT2rROWo6AuLItD19rx1KH81dCLccnETzXXw+5j1CxrX0e3V5N3XPja40IuNde/6zYanxr9Xs2lhZ1K8GrVK8G8JsAfgLAr+ScH79cvxHAm3LOX5dSej+AW3LO9yz3Pgzg6TnnTxBbtwG4DQCuxFVPe1Z6rtt5wEeAUv2WndxKFF6ltidGTXpp3FpyYhHjt9Uz6Mnr1fLX0rXyeonoaKXV1haquYXkdwv/ASCl9JMAHgDw4wgK/3s//C/tMJ4UQa8i5mzQHCK1F024WxK2RakCtj8UoGhRq0caO4sfHjKrjXn0mUIURgoOLr/qJVGKyIOqRwP4TM75/pTSFwH4HQA/C+BWAL9RHFTdmXP+lymlHwHwdcVB1d/MOf8trY0R/6Jas1XCkr+q5QstimvLA5rR8CoODq1kuze2eH6ti98y1zzzf09soVS9ZSNJ9WYArwJwGYCHAXhtzvmfppQeh89/pOoPAPztnPOnl49g/VsATwHwSQAvzDl/RGujR6lGhIISPOq2lhaQJvyeJLs1QdDrHEaRbUuqwVtGK9eqvL1qTiPSEQQ7cg6NSgG1KuRDffi/plT3hHXiWdXsnjnByE1oVG5sNmXbS7gtz92ad5baWSGln9Z7XJvcvVE4WtR2KFKl31JFsWVuzWKfwjvpIwlpRH9H5jN7SIZDC9lq9aIJ0gPpMCoqDKZkvcKqbLfEFuvY2+/Qj1RtDe9CKct7H4T34Y1SaFy9WkrB448HXpstPowYx1bFSutJbdLnEgX6fMv3lvC35i+dU7VcK0fE9LrmzxEg5awj+jGNUr3/3msftIPSCVZeW69LD5+WtSA6PyvlVGvtW1SCdUws/kapIi+khR2ZK6P3KGqqM4Kka/nk6DHQfNL6Sw/HqH8tKYlIzHAGcdjwv0QtXLGGxxSRD8W6QFoOGGgb50kpWNHSN0/aZHQOt0ZW2nULIlI1GtFSv2ZIDWgYSb6HI9VVqQK+k1agniMqy0sLyZu71CYXt6tbFAL33upTZO4tAtG5Y6udFZFRRwlPtKTVLcvPSlArenK9EXli7xpptV+rdyhSXf/2X9oNe9RKa1hdwkKm0oPRHlgUoXJ9mH2hbgXP+Gv1y/cSvFHTls8oQsFpud+jwsoLt1z/5GOR6hr+9xBPLXzWiM4y4Wq53lp6oie8t4BT4VHqL9LOiFyq14cR7dZU6orZCKhF1QHxxDpDCktbrxcvHfyb/wHfDkJfa2WoTY0cufatKQePKmmdUBpJeCf7DJO6Bz0KUrJ35PGIgFUI7KFYe5+PNUoBPt+vQyrVFRJZtijMEpZcDOA/3ZXItSW8rLXHtaPZbFVne5JKxIJZoaVk9kCvMuxtNyoPX/pW+hc156PhSf9JZQ5Hqvffey0AOXReoV1b4UkFWKERJ+eXJRTv9bM1rxq5sFoQ3eaI5z0SLSppq3a5si2ptUiMUKU0XWbpwyFJlSMiLldY3i9Ry/doIbmHpDWSjw63PSQttTEjsQDHWJDRiOjzFn1qiWii0litvrTCunYPRarlN/97ScmTV+UImu5WWl5S2/F6EDkZa6mTSIxsa0s129tmZBhdokV9b5FrlOrMtoEB/rHSOOSwB1Xe/GGJ1nC4ZqemgMs6EYs3kpS0MGcmSBvbqLZ6Nsetc7SjNvMobPnsLL5EbEacSDiUUq199Z+UAmghploO1JLH3TN8i6w7Ur3NgD3SCTOq9C0wq1r1+qOl+qxK9WFOH3fB2slbrn/yg35KXLx0x4N+1ge8/nCgA8iRJ3eflinf96C00RISSjY0WzW/o0PwkXU9m26trnf8W9pc26E/5fWt0dvmiDRIT3mvP+V6lnighimUaus3/2uhrRTuelIEUt7WYrfm84jrFrWwhdKKwB65wVGw+jKLz6Nyy0eZexKs4f8USvWDd16l3q8pqnUnKXd5urvQnZ9TB6W6LctJhzE1nyi85TVo6RBP2z3qztqG5X6kHxH1KXoUnBRO1tqJjn4s5Wqio6fNaJXf40tUeQ5TKFXrv1PR8pzlNa6Opbyk9DQF2Juz6UWvQvbY3hpehdfS963U095j6cEeUUJPm1uN7aGUqhU0n1oqUk6Vcoq1tFOiJfy2XOP6QMtbVaTFnpbjrbXX6oMX1nyhN2SWFKEW6USopxG5vdZ2IrBlXjSizdk2q+lJtSVcKomWC/G5urXQvyxTonZf83MkuI1E80mz00P6ks2ohSDZsaj3KGy1qHuU3AhwdlsEiCctZPGppb+RYzRl+F87DLKG/CW4AydrusB7SLUlPG3XwuQe2+cN0Wkd79i3YI+wXbLRmwKwprW2xOHCf6omOUXJqS+643E2NIVZ1inTBVyb2uGXZYe07MheG72HChoiFpj23msjol9Wey0Hh5rdlkNEDyykU2tHyzt77HggpWksQsZqd2tMQ6o0V0rvrde5kJy+LkP5ctfkiJTakB4qTSNw/mmhcgkpZUF94ep51VOPn72opSAsaQUtYuj1qUaEElrJKap8q43WdiyppNY2akKp9Rn1rJNeTEOqFFQFArJS5B4CVaplHekel+uju6e0m9aIStqRPbAokRE7+CgCtuRDOV+sqQvudc0XD9HXyln88UY7tXb2QEseU1K/2lrSUgM9/kWnFaYiVa7j3ADSCV4q0xo4Baq1X7ZBbXCvywlhWYi94SA3FtGTxBoW1hChMK19k54R50vrc7KWs0RX62urmm99xq2bqpYCkMSIBrpOuDysxgde1bplPnYKUr3p5gfYgZVCdk6xWsmSSyHQMtQOp5pLaOkJrpzWrlSOQ63fo7FHmLuit5+S6hkBC8FY73HzUrpWm6s9/kdETdoapgKF1olIBY3ClKf/JaT8Gr0m1S2JOnoBlSSv2ZZ2YKlelJ+a7S3IZGTftgJN9WzVJp23JbwbwtZj7p1j0hq39HPL53Po0//yGlWrQD0UlEhL2/WpH5JS5XytKV/vZmANAa3Ycjev9TFSYWjPiPPHYouiN3/agnK+SqRB+16+puOhjfnoueFVxGW0RyM/ad1FEWrUWEypVCkpSq8tSq+2a3IqcrRyHK0ctL4CdWXNlZ8dMyvgFt+0TdljSyLWEWPVGhnWfPSu0cg1XNY7lFJdc6rcA6c7EQ2HvOGPtIuv9zjUFHH5Wtvt6ESz1LHct/rbkgON2kwiy3JlZiVUwO9bOTepmGh9hpwNbv72gCNSLQqkdcvynFLV/NRUvXTNgpZ6UylVyw5XU6G1nVh6SNpOyO3AWhu19iKVsNT3mjKPVt9b1N9bjUa071VUXmXpmQP0fevm7V1zFr85+542LbDYOLRSBR4a1lshTRxOCXIPRdsJORKiuz/XjqaEaRtazkvzi9ov+xKlVmvYkuT2VqMWxeSxUVvMaxlPpGSdA9yaaFHUFmKy9nN9z6lrqXzNPw0WG4dWqrX/prqCU4se9WVVw6Xt9XVZ32OPq9eDmvrd0pca9laXs0OKvABb2skbqXFt9ypVqT/adY7UubKSmq/Vq6FF6R72f1TVJpk04NKErD2gEhaiLW3XYJ1glvY1n7x9jU4B7ImIBSbZHT02tbls9atlbtZsRsBDiFzdtZyUDohMxVhwyPBfghTScK9p6LCCTlpuV5aIjtovr9NypX0pReDZsSV/yjCpfN8alkqIthfdvhQejyTUqDHxKjpOka526DhwqQEOIzcP6blYw+5y419fa5vo3nN1xRSkuv47FfqAJZKRBk8iSlpPI176mpvE3ES05qmk91rbHCQ7Urut2FvJ7tF+rU1uTnGwlFnvS21KSrasa9l4LH5ar/eAW3OaeKBKVRMk3rkyam5NE/7ff++1AHhyksL/FVo4W8s3SXkl7uHVlGzNTw+s9b2hfG2sSrT6z6ktT9rF25do1OZRry3pfkt6SpvTHh+pjV54bVp8jvbTOt5ru9Z/UW0m1ZTSZQBuB/C/cs7PSyl9NYDXALgGwLsBfF/O+c9SSlcAeDWApwH4BIAX5Jw/qtmu/TfVEhwpWBellXQpuPa46zU/vdBCwbX9XtQmakSb0eS3JZlG1qsJAkDODbcQpXUNeDDKrteHFd42e/wMP6hKKb0YwAUAj1xI9bUAXp9zfk1K6eUA3pNzfllK6UUAbs45/1BK6YUAvjPn/ALNNj39t04sTWVadz5KzJxK9k4iq6LQ/OLKRqgSS7sraru4texoRI/Bln2xkGargh1FOL3EepRNliKUVFNKNwB4FYCfBvBiAN8G4I8BfFXO+bMppWcC+Kmc8y0ppYvL67enlC4H8IcAHp2VhuiH/wFbWNSiUDUy6A2luR20V6lK9karKs4H6otWfg+S3SrlEoXas9xys6gp5Wh/LIiM8lrLlfejSfV1AH4GwJcC+AcA/g6A3885P365fyOA3845/7WU0vsAPDvnfM9y78MAvj7n/HHJ/oUnXZnfefFGNgySpH6NcNbr0jXuPhfeS7CU71EfkRihZKyKnis7E0YqupqNEh4lGk02W5OlhBZFHmHHajeMVFNKzwPw3Jzzi1JK34QzUv0BAG8npPqmnPPXpZTeD+AWQqpPzzl/gti9DcBtAHAlrnras9JzTfk9jli1nTQi30Xf70WIe09+yyZhJYtR+eEZyCECtZRXpG3vHOuN6Hp8lt7Xrkcg8nOq3wDg21NKH8XZwdQ3A/h5AFcv4T0A3ADg0vL6HgA3AsBy/8sAfJIazTm/Iud8Ied84a/e/OdqHnIFN1hcnbWeNvD09/rQuXCXa3Mty5Wn9q2ohdotimr9bfHF6i+1W47zLdc/+UE/tFy5EVrKeXyUUjxe9NT31NX6WY4nd73HB2rbO69a67VAElp0ztDrNXsjUSXVnPNLc8435JwfC+CFAN6ac/5eAG8D8F1LsVsBvGF5/cblPZb7b9XyqcDZ51Qt+R4KKfzWiJSrX77nSKysy5EIbUfala2T3VLWYpcSXY1caxOSW4x0zKR6XFk6rrS8hN5+1NBT31rXki7RNmyPD54NqqXvLURlrRPtzxYbQc+H/38cwItTSncDuBbAK5frrwRw7XL9xQBeUjO0/kWVRg6a6uLypHRiamVo27XFTsmFU8bcTqopqZ5w2FrWQoDUn5Gqj4acEhlICpdTzFsokUhoG6klMqPwEKUnOtPa8qZ4aLqhVk8DN2/2TgG5SDXn/Ls55+ctrz+Sc356zvnxOefvzjl/ern+/5b3j1/uf8Rqn4aC0qSqkSy1VV7j3nPtUjL1hGoaoWv9WrF1+KotRKlPrW1w9aUUh/R86KZZSyVsDW8aZYU1wtLgsVGOXctztUY2XJtSmZYITyqr1bOWa8E0f1FVfqHKColoasRLQUPyWojOtSvtrBwZc2WpUpbszwzreI8sK9WnsJDLXmOuzb+t2uPm+Sif9pjjI/pz2C9UkfJ00rWagpKUp1TfCkqclKxpX6SJZckf7oVa21G5q15CpUqVU6uSoi3ttIy1VQ1xsDz3iOdPo44etPhTrgHLeEVEGBZCHbW2plOqwENzLpKa5FSkRKBSfS23w+3knB0P9lKmnGo+gjpuhRZx1OYHrVOWixg3y2If/Wxa526UX9Z1EOEnxyctdg+pVDmVyb3XcjLldbqAuDrlrkiVDM3b0Z203H2tikUj8dEoFVrkoq1FC6NhecbrNapYaRn6rDRV29pPaV5S37kyWi6wNgct/nLjoBGgdQy01EstyvTarxGq1H4UpiDVFVxovEIbcG7RSDalRcOFjFKagJITDW/oJNHUkXdxSotKIrZWZezxSSPqnvDY275237qZSPfpc9LSNhrpeojN4590r9aeZZ542+RscxsJXa/SeraILU1cUV+ojeioYIrwX/qWKok4tftlGS18s4RgJSRylsJC7aFp4clsoOPV6+vWfR3ZnmdMPIuYI6GtxsyzPiw+WcdGS9P1oCYqPGN8qPC//JJqCbVwjQvbOXXCqc8SUiqA+mche06RSgtG2429YbU3LNQgqQmPDWqvFS3K1kN23rY4hVU+Kykq8vgjpR8s8EZBtN2e+2U5KYKjr+k1SxrEMn85O+VapLwhtWXFFEqVHlQBMlmt12pqj9txNTW5oqZoNfUr+UJhVcna7uohpyiVeQTUohtLvYi26bUW1VmLElp9jrCnrR2uLVpPWmd7RDKlP5zPKw71j//W8J8b4BXagFsIlKuz2pXs1cpbQvzaotJIoNYvaUJ6yETqb2T5PdC6SD1zqMWfraHNIWm+WNSf1h61pUV6kr/Se+r/aqvleVuEWenroUjV832qdCDX1xQjdz6rSq7VWaFNsPW+1oZWztoHy71avyxtH0k1R/no3eRafOhRnxGbsTZnVpu1dloJ1eJfzcca8V+8dEf8v1MZifX7VFdID8D6ELUdl9utS/u19rn7rYpY81fru2ZD80Prews85Ou10WJrBGYgVs6WNZJqmTM9SlXzp1ZGi7ykNacpcK2/1jVT+nc4pbr+OxWAV6McvGGaZ2At9yQSLH0r69CyXH+5spZ+0bIW0vdsWJq/syOC/D12o8rX6nqjhFZE+F2LNtf3UpstmwYtb+2PVPdQp//ln6muHeaU1Hq9LFveX99fvCSfeq73yrLl79IHDaWfpX+0HQpJBa/vS7u0Pe41rS/5z/kj+V7rO/ccaupGQ09di90tyN/ShxY/tFDZ6wc31y22auJG84HW5ea3tKY5wpVs0znIrQmuPXrPcr+GaZRq+YUqVvXIkVOL9OcGtRZiUPtrPe0656+lnxI84Q53TQuruDraOFiUgTVUa4VFkc6u6LxltLFt8a01emstLxFn7zPycoIFh1OqpUrjlGQJer+m7Mr3lNhWUMUmEQm1Te/TMtKOTOtwas+qKLjJIV0r29H6LG0InP8StM2GazMatWdAy41WzBqshKqpKrqGPPbLNlp9rPmrzXX6jOgzkdae5iu32Uh9iXz2U5Dq+s3/3MBK18pFSQlzvb5eKyGRZm1haQ+Es0vDD1qWI7aaalz9KBdPzVduEpfk6uk3d4/676lTQiM7qz/UBqekuf5GEbwU/WhRUQ3cPJFIia4Lrb3avLTWkSD5y/lpUZHceteeL61XvtbmQAS5ThP+lwdVQD2053YgacApJBWmPSxLiCW1RScr10+ujvW91Jbkq0XFWMbRUqfmU20creNsKe+15WnLYtvTfo+vnmcXNSae9VCCExI1RWlZi5yIqNWr9eFwp/9STtVKFBKsE19rtxZOccRrIS6L39ok5PykNji/POWk35yvUh+i4V0Ms2AkgXk27Rb7nrqrD9ZoSlpLtfIcJ5TQRJPWjrTGDpVTBXi1yYWXdODW0KK8Ll2TwhstFKLhlPQQJNvlPeqX1heufSuhljYsk5qD1G/OHtc2d70F2rPh5kwU6Nyx+qfNL2nxeyGNN+cDHSsOXgGg2SrnnCU60p4dV0dSsvRajVDp2tDUvXeDmUapruG/Rn4cqazXV9SUWFlGU1hlm5wdjsisvngVn9YHDd46Xn8t9aRrFnsexVR7Htb7o9VkTfXvCevzabXBEZxUV7LVqn5r61gj1UMq1ZtufsCshOhrTtnSnVnaubhdrhzc8r6k/Gh5SYVy/lPVytWXJgr1gVPnax2OQDh1QxV1rU3NLw/BSeU4f7Rx1XziNuJWAtFUbDlX6HU676II1aOWpfvUn1bfNBtavyWxVI6nRI70mdZ81+arxAWaOqeYQqmWX6iyQiIvDlHqTtsZtTBCswFj4mEAAATnSURBVGXZPTk/Lf2idjUlxPnD+SW1LxGF5qdUV1Mw3LPSNkILOXsVcg1eRWft/4zo9U1TmNZ5ZvFHEhPc2uXul9cl/w/1t//a/6ii1yxkt5an7y31aPvcbmWdBLV+rJAWf9mutltaJqF3slr6WutDrR3LApHGT7NdW8itJNHbNy8ZbwnrPIlqp6WO9Xlq88pTn/4+VPgPPFjKc1Kchg4lyax1pHCDlpfuaaQlPaiyLheOcOW531x5qT79Kdu3Ei/1lV7n+iaNubbhSKq6tM+1a1F/9Lc2R2gZrt3ymuSXNL50fmjPXhtzyf5W0DasCN9qm1L5m76W5jD1URrn2iYn2fZuAtOQqqQepUm/3qfgHnw52JRAKWFyqlCzqe2Kmg3tgZZ9k0iOluUITvOHI3WufWqXEiHto0aO0sYjLSaOAOnzon5pc4R7xpb+U5+050X9lWxLBNyiEkeTXVmmpS1tI+J8oONRPjeJ7Dhh5d3gNT88/Z6CVMsvVAH4yb9e1xZCWXetTxcnJVdah7MnqWBKNlKdGkFzxMJNglY1WP6W2uE2F9q2pLIl1SqRLEdOFnXqmeQWAqgRatkWHSPNtldl16CVr60HKywbQfmb1tNsWse55gs3v7RNtaY2a4KtFE4eTJNTvf/eaz/3npu00sPkSI0+TEmJSnW1stQ/SkKaH5xNrSy9x7XH+SPZqvWda5cbQytq/dd8rPkjleU2BotCbRkbant9r42bZNeywdfA+SCNt2eca+WtvmnjUPOnhHX8anPN4ktpw3pQNY1S5ZRfuTtquwY3sTmi4dTWCnq/vF62U9avTVCqvjRylJQk56tkX3otLTYKbXfn7FnUDVUQnO+1TYPzgZaVNhXNXtkfybbmi2Xse54zp6Q437n+Sr+typJTbj3Qxpd7z607qQ/SXObsc3U5XzTRVsOUShWQd1RrBzXlUF6XXlsUo8UXrm2PX6UNi8qpKRNt47AqqprK48ppSsk7aaUxpX2Q2rEoXKlO6zOX3nP1WlRhr5LcGpZ1XVOQQD0ak9rl1tsKaRwP97f/9AtVVmiLU9t1a6TsDXGkehbyKN/TOhai1PrB1VnrWcbOSrAtfZLar7WrbTY1grMsRGl8auNAbdY2aKm+5m8NtG1LGx6MJGfPRk3vSXOwvMbV8W5u2to83EeqNIK4eOmhYena4TIsKN9rhMvZLh/Eer+8R+vXHnJ530I+Uj+pba4N7l5ZRhu7su3SX1qn7ANXl96n/aTPi2tX6zdtS1qIEhmXfmukQX2l9yRwC5H6Qn/XynD95+Y61wetfxq8BN9ruyYOyrrcHJHWATcnS9t0bnI+luun1rcS0yhV6cP/FoVmuafdtyigsiyg73BanVYfJV8t/eLeW32yjH9tYVjVpLThWFSpVWF51JL1mqed9R7gV5hepVebzz3Ksdfn0fU58rTyCC2z/j5U+J9S+lMAH9jbj0Z8OYCP7+1EA47qN3Bc34/qN3Bc3yP9/ss550fXCl0e1FgvPmDZAWZESun2I/p+VL+B4/p+VL+B4/q+h9/T5FRPOOGEE84DTqR6wgknnBCIWUj1FXs70IGj+n5Uv4Hj+n5Uv4Hj+r6531McVJ1wwgknnBfMolRPOOGEE84FTqR6wgknnBCIE6mecMIJJwTiRKonnHDCCYE4keoJJ5xwQiD+P4dc5PjB9n8EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4c31ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grad_ms = get_grad_mask(val_image_s,synthia_size)\n",
    "grad_md = get_grad_mask(val_image_d,synthia_size)\n",
    "plt.matshow(get_grad_mask(val_image_s,synthia_size)[0,:,:,0])\n",
    "plt.matshow(get_grad_mask(val_image_d,synthia_size)[0,:,:,0])\n",
    "print(np.mean(grad_ms))\n",
    "print(np.mean(grad_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_rgb, target,mask_t, d_flg = interpolation_model.get_placeholders()\n",
    "with tf.device('/cpu:0'):\n",
    "    input_rgb, target = next_element_rgb, next_element_d \n",
    "    mask_t = random_type_mask(input_rgb, mtype = 'rand')\n",
    "    y_true, d_input, m = interpolation_model.preprocess_depth(target, mask_t, synthia_size)\n",
    "    gr_input = interpolation_model.preprocess_rgb(input_rgb, synthia_size)\n",
    "G_output =  interpolation_model.model(d_input, m, base_filters = 32,p=0.5, d_flg = False, use_bn = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from vgg.vgg16 import VGG16\n",
    "#vgg_model_true = VGG16(vgg19_npy_path=vgg_npy_path)\n",
    "#vgg_model_gen = VGG16(vgg19_npy_path=vgg_npy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    #vgg loss\n",
    "    #exp_out = tf.exp(G_output)\n",
    "    #exp_true = tf.exp(y_true)\n",
    "    exp_out = G_output\n",
    "    exp_true = y_true\n",
    "    y_true_normalized = (exp_true - tf.reduce_min(exp_true))/(tf.reduce_max(exp_true) \n",
    "                                                              - tf.reduce_min(exp_true))\n",
    "    y_true_3ch = tf.concat([y_true_normalized]*3,3)\n",
    "    \n",
    "    gen_normalized = (exp_out - tf.reduce_min(exp_out))/(tf.reduce_max(exp_out) \n",
    "                                                         - tf.reduce_min(exp_out))\n",
    "    gen_normalized = (exp_out - tf.reduce_min(exp_out))/(tf.reduce_max(exp_out) \n",
    "                                                         - tf.reduce_min(exp_out))\n",
    "    generated_3ch = tf.concat([gen_normalized]*3, 3)\n",
    "    \n",
    "    \"\"\"\n",
    "    vgg_model_true.build(y_true_3ch)\n",
    "    true_features = vgg_model_true.conv3_1\n",
    "    vgg_model_gen.build(generated_3ch)\n",
    "    gen_features = vgg_model_gen.conv3_1\n",
    "    VGG_loss = tf.reduce_mean(tf.square(true_features - gen_features))\n",
    "    \"\"\"\n",
    "\n",
    "    #generator_loss\n",
    "    tv_loss = tf.reduce_mean(tf.reduce_sum(tf.sqrt(tf.square(G_output[:, :-1, -1:, :] - G_output[:, 1:, -1:, :]) + \\\n",
    "              tf.square(G_output[:, :-1, :-1, :] - G_output[:, :-1, 1:, :])), axis=[1, 2, 3]))\n",
    "    #G_loss = tf.reduce_mean(tf.square(y_true - G_output)) \n",
    "    square_loss = tf.reduce_mean(tf.square(y_true - G_output))\n",
    "    G_loss = square_loss# + 5e-5*VGG_loss\n",
    "    #G_loss = tf.reduce_mean(tf.square(y_true - G_output)) + 2e-6*tv_loss\n",
    "    #GC_loss = tf.reduce_mean(tf.abs(tf.log(GC_output  + eps) - log_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = tf.constant(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('opt'):\n",
    "    #optimizers\n",
    "    all_params = tf.trainable_variables()\n",
    "    first_stage = [p for p in all_params if 'G_Depth' in p.name]\n",
    "    lr = tf.placeholder(dtype=tf.float32)\n",
    "    train_G = tf.train.AdamOptimizer(lr).minimize(G_loss, var_list = first_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('summaries'):\n",
    "    loss = tf.summary.scalar('loss', G_loss)\n",
    "    mae = tf.reduce_mean(tf.abs(G_output-y_true)/(y_true + eps))\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(G_output-y_true)))\n",
    "    mae_summary = tf.summary.scalar('MAE', mae)\n",
    "    in_summary = tf.summary.image('input', d_input , max_outputs=1)\n",
    "    out_summary = tf.summary.image('output',G_output , max_outputs=1)\n",
    "    gt_summary = tf.summary.image('gt_depth', y_true , max_outputs=1)\n",
    "    all_summaries = tf.summary.merge([mae_summary, in_summary, out_summary, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "ground_truths = tf.summary.FileWriter(logdir=os.path.join(log_prefix,'img_gt','s').replace(\"\\\\\",\"/\"))\n",
    "ground_truthd = tf.summary.FileWriter(logdir=os.path.join(log_prefix, 'img_gt','d').replace(\"\\\\\",\"/\"))\n",
    "writer_grads = tf.summary.FileWriter(logdir=os.path.join(log_prefix,'grad','s').replace(\"\\\\\",\"/\"))\n",
    "writer_gradd = tf.summary.FileWriter(logdir=os.path.join(log_prefix,'grad','d').replace(\"\\\\\",\"/\"))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[5,32,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: G_Depth/convolution_2/Conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](G_Depth/AvgPool2D/AvgPool, G_Depth/convolution_2/Conv/weights/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/Mean_1/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1806_loss/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'G_Depth/convolution_2/Conv/Conv2D', defined at:\n  File \"D:\\Python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\Python36\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\Python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-155-980f004ad4a0>\", line 7, in <module>\n    G_output =  interpolation_model.model(d_input, m, base_filters = 32,p=0.5, d_flg = False, use_bn = False)\n  File \"D:\\Alice\\OneDrive\\code\\models\\interpolation_model.py\", line 343, in model\n    bn=use_bn)\n  File \"D:\\Alice\\OneDrive\\code\\models\\interpolation_model.py\", line 158, in projection_block\n    normalizer_params={'activation_fn': act})\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1057, in convolution\n    outputs = layer.apply(inputs)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 762, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 652, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 167, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 838, in __call__\n    return self.conv_op(inp, filter)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 502, in __call__\n    return self.call(inp, filter)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 190, in __call__\n    name=self.name)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 725, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[5,32,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: G_Depth/convolution_2/Conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](G_Depth/AvgPool2D/AvgPool, G_Depth/convolution_2/Conv/weights/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/Mean_1/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1806_loss/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,32,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: G_Depth/convolution_2/Conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](G_Depth/AvgPool2D/AvgPool, G_Depth/convolution_2/Conv/weights/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/Mean_1/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1806_loss/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-23dca066ef0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_G\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0md_flg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mmse_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mll\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,32,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: G_Depth/convolution_2/Conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](G_Depth/AvgPool2D/AvgPool, G_Depth/convolution_2/Conv/weights/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/Mean_1/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1806_loss/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'G_Depth/convolution_2/Conv/Conv2D', defined at:\n  File \"D:\\Python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\Python36\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\Python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-155-980f004ad4a0>\", line 7, in <module>\n    G_output =  interpolation_model.model(d_input, m, base_filters = 32,p=0.5, d_flg = False, use_bn = False)\n  File \"D:\\Alice\\OneDrive\\code\\models\\interpolation_model.py\", line 343, in model\n    bn=use_bn)\n  File \"D:\\Alice\\OneDrive\\code\\models\\interpolation_model.py\", line 158, in projection_block\n    normalizer_params={'activation_fn': act})\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1057, in convolution\n    outputs = layer.apply(inputs)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 762, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 652, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 167, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 838, in __call__\n    return self.conv_op(inp, filter)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 502, in __call__\n    return self.call(inp, filter)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 190, in __call__\n    name=self.name)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 725, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"D:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[5,32,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: G_Depth/convolution_2/Conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](G_Depth/AvgPool2D/AvgPool, G_Depth/convolution_2/Conv/weights/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/Mean_1/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1806_loss/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "epochs = 1#35\n",
    "n_batches= len(synthia_depth)/batch_size\n",
    "\"\"\"\n",
    "ground_truths.add_summary(gt_summary.eval({input_rgb:val_image_s, target:val_gt_s}))\n",
    "ground_truthd.add_summary(gt_summary.eval({input_rgb:val_image_d, target:val_gt_d}))\n",
    "\n",
    "\"\"\"\n",
    "i = 0\n",
    "rate =  [1e-4]*30 + [1e-5]*30 \n",
    "saver = tf.train.Saver(max_to_keep=15)\n",
    "\n",
    "for e in range(epochs):\n",
    "    i = 0\n",
    "    sess.run(training_init_op)\n",
    "    mse_loss = 0\n",
    "    \n",
    "    for _ in range(100):\n",
    "        _, ll = sess.run([train_G, G_loss], feed_dict = {d_flg:True, lr:rate[e]})\n",
    "        mse_loss += ll\n",
    "        i += 1\n",
    "        print(i)\n",
    "        \"\"\"\n",
    "            if (i + 1)%10 == 0:\n",
    "                mask_uni = np.random.choice([0,1],size=synthia_size, p=[1 - 0.1, 0.1])[None,:,:,None]\n",
    "                sum_grad = all_summaries.eval({input_rgb:val_image_s, target:val_gt_s, mask_t:grad_ms, d_flg:False})\n",
    "                writer_grads.add_summary(sum_grad, i)\n",
    "                sum_grad = all_summaries.eval({input_rgb:val_image_d, target:val_gt_d, mask_t:grad_md, d_flg:False})\n",
    "                writer_gradd.add_summary(sum_grad, i)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "    sess.run(validation_init_op)\n",
    "    for _ in range(100):\n",
    "        sess.run(next_element)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for e in range(epochs):\n",
    "    try:\n",
    "        val_loss = 0\n",
    "        val_b = len(synthia_rgb_val)/batch_size\n",
    "        batch_it = tqdm(SynthiaIterator(synthia_rgb_val, synthia_depth_val, \n",
    "                                        batchsize=batch_size, \n",
    "                                        shuffle=True, \n",
    "                                        buffer_size = 70), \n",
    "                        total=val_b, \n",
    "                        leave=False)\n",
    "\n",
    "        for xb, yb in batch_it:\n",
    "            #t = np.random.choice([21, 31, 51])\n",
    "            mask = get_grad_mask(xb, synthia_size, 51)\n",
    "            #p = np.random.choice([0.05, 0.1, 0.2, 0.4])\n",
    "            #mask = get_mask(synthia_size, p)\n",
    "\n",
    "            ll = sess.run(mae, feed_dict={input_rgb:xb, target:yb, mask_t:mask, d_flg:False, \n",
    "                                                           lr:0})\n",
    "            val_loss += ll\n",
    "        print(\"epoch {0} val loss {1}\".format(e - 1, val_loss/val_b))\n",
    "        \n",
    "        \n",
    "        mse_loss = 0\n",
    "        batch_it = tqdm(SynthiaIterator(synthia_rgb, synthia_depth, \n",
    "                                        batchsize=batch_size, \n",
    "                                        shuffle=True, \n",
    "                                        buffer_size = 70), \n",
    "                        total=n_batches, \n",
    "                        leave=False)\n",
    "\n",
    "        for xb, yb in batch_it:\n",
    "\n",
    "            mask = get_grad_mask(xb, synthia_size)\n",
    "            #p = np.random.choice([0.05, 0.1, 0.2, 0.4])\n",
    "            #mask = get_mask(synthia_size, p)\n",
    "            aug = np.random.choice([0, 1, 2, 3])\n",
    "            if aug == 1:\n",
    "                xb = xb[:,:,::-1,:]\n",
    "                yb = yb[:,:,::-1,:]\n",
    "                mask = mask[:,:,::-1,:]\n",
    "            if aug == 2:\n",
    "                xb = xb[:,::-1,:,:]\n",
    "                yb = yb[:,::-1,:,:]\n",
    "                mask = mask[:,::-1,:,:]\n",
    "            if aug == 3:\n",
    "                xb = xb[:,::-1,::-1,:]\n",
    "                yb = yb[:,::-1,::-1,:]\n",
    "                mask = mask[:,::-1,::-1,:]\n",
    "            _, ll = sess.run([train_G, G_loss], feed_dict={input_rgb:xb, target:yb, mask_t:mask, d_flg:True, lr:rate[e]})\n",
    "            mse_loss += ll\n",
    "            if (i + 1)%10 == 0:\n",
    "                mask_uni = np.random.choice([0,1],size=synthia_size, p=[1 - 0.1, 0.1])[None,:,:,None]\n",
    "                sum_grad = all_summaries.eval({input_rgb:val_image_s, target:val_gt_s, mask_t:grad_ms, d_flg:False})\n",
    "                writer_grads.add_summary(sum_grad, i)\n",
    "                sum_grad = all_summaries.eval({input_rgb:val_image_d, target:val_gt_d, mask_t:grad_md, d_flg:False})\n",
    "                writer_gradd.add_summary(sum_grad, i)\n",
    "            i += 1\n",
    "        saver.save(sess, os.path.join(log_prefix,'model_{}.ckpt'), global_step=e)\n",
    "        print(\"epoch {0} train loss {1}\".format(e, mse_loss/n_batches))\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        batch_it.iterable.stop()\n",
    "        raise e\n",
    "        break \n",
    "# save model after training\n",
    "\n",
    "\"\"\"\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()   \n",
    "restorer = tf.train.Saver()\n",
    "#restorer.restore(sess,'/mnt/storage/experiments/deeplearning-semidense/out/two_sec_vgg31_ps/model_34.ckpt')\n",
    "\n",
    "restorer.restore(sess,'C:/Users/Dell/Documents/Experiments/deeplearning-semidense/out/two_sec_vgg31_ps/model_34.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthia_depthv = synthia_depth_val\n",
    "synthia_rgbv =  synthia_rgb_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bs = 5\n",
    "val_loss_l1 = 0\n",
    "val_loss_l2 = 0\n",
    "val_b = len(synthia_rgbv)/bs\n",
    "batch_it = tqdm(SynthiaIterator(synthia_rgbv, synthia_depthv, \n",
    "                                batchsize=bs, \n",
    "                                shuffle=True, \n",
    "                                buffer_size = 70), \n",
    "                total=val_b, \n",
    "                leave=False)\n",
    "vals = []\n",
    "rmse = []\n",
    "ssim = []\n",
    "for xb, yb in batch_it:\n",
    "#for xb, yb, name in sy_gen(synthia_rgbv, synthia_depthv):\n",
    "    #z = np.zeros((1, *synthia_size, 1))\n",
    "    #z[:,::7,::7,:] = 1\n",
    "    #mask = np.concatenate([z]*bs)\n",
    "    #mask =  np.concatenate([get_mask(synthia_size, 0.17)]*bs)\n",
    "    mask = get_grad_mask(xb, synthia_size)\n",
    "    #plt.matshow(mask[0,:,:,0])\n",
    "    out = sess.run(G_output, feed_dict={input_rgb:xb, target:yb, mask_t:mask, d_flg:False})\n",
    "    res_gt = np.zeros((bs, *synthia_size))\n",
    "    for i in range(bs):\n",
    "        res_gt[i,:,:] = resize(np.log(yb[i,:,:,0] + 1e-6 ), synthia_size, preserve_range=True)\n",
    "        \n",
    "    score = np.abs((out[:,:,:,0] - res_gt)/(res_gt + 1e-6)).mean()\n",
    "    score_rms = np.sqrt(np.square((np.exp(out[:,:,:,0]) - np.exp(res_gt))).mean())\n",
    "    score_ssim = 0\n",
    "    for i in range(len(out)):\n",
    "        result = (out[i,:,:,0] - out[i,:,:,0].min())/(out[i,:,:,0].max() - out[i,:,:,0].min())\n",
    "        gt = (res_gt[i] - res_gt[i].min())/(res_gt[i].max() - res_gt[i].min())\n",
    "\n",
    "        score_ssim += compare_ssim(result.astype(np.float64), gt)\n",
    "    score_ssim /= len(out)\n",
    "    if score < 1.1:\n",
    "        ssim.append(score_ssim)\n",
    "        rmse.append(score_rms)\n",
    "    #if score > 0.2:\n",
    "        #print(score)\n",
    "        #pict = np.zeros((synthia_size[0], synthia_size[1]*3))\n",
    "        #for k in range(bs):\n",
    "            #pict[:,0:synthia_size[1]] = mask[i,:,:,0]*res_gt[i]\n",
    "            #pict[:,synthia_size[1]:synthia_size[1]*2] = out[i,:,:,0]\n",
    "            #pict[:,synthia_size[1]*2:synthia_size[1]*3] = res_gt[i]\n",
    "            #plt.figure()\n",
    "            #plt.matshow(pict)\n",
    "    vals.append(score)\n",
    "vals_filtered = [v for v in vals if v < 1.1 ]\n",
    "print(np.mean(vals_filtered))\n",
    "print(np.mean(vals))\n",
    "print(np.mean(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
